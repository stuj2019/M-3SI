# M<sup>3</sup>SI-Net: A Fusion Model for Facial Emotion Recognition with Inception Blocks and Re-parameterized Swish1 Function

## Authors:
Sabyasachi Tribedi and Ranjit Kumar Barai

## Abstract:
Facial emotion recognition is an important topic of study in artificial intelligence
and computer vision. In this paper, we offer a novel automated system
for facial emotion identification that uses fusion approaches and a novel model
architecture based on different flavors of MobileNet. MobileNet is widely used as
a lightweight deep learning model; nonetheless, its application fusion technique
with a range of its own flavors is novel. This paper introduces M3SI-Net, a novel
facial emotion recognition model that leverages a fusion approach based on variants
of MobileNet (MobileNetV2, MobileNetV3Small, and MobileNetV3Large).
The model integrates Inception blocks and a re-parameterized Swish1 function to
enhance feature extraction and classification accuracy. Through extensive experiments
on the Jaffe and Cohn-Kanade datasets, we demonstrate that M3SI-Net
achieves state-of-the-art performance, outperforming existing methods in terms of
accuracy, precision, recall, and F1-score. Our approach provides new insights into
facial emotion recognition and showcases the potential of fusion models in improving
the accuracy and robustness of deep learning-based systems. This research
looks at the importance of face expression recognition, which is important in
human-computer interaction, affective computing, and a variety of applications in
healthcare, entertainment, and security. Because of the intrinsic complexity and
diversity of human face emotions, we needed to come up with creative solutions,
which led us to use siameze learning approaches. The Siameze multiflavoured
mobilenet model for a data fusion-based technique is a fundamental contribution
of this work, boosting its expressiveness for greater adaptability. Our technique
effectively leverages different information by merging multiple base models with
various pre-processings, resulting in higher facial emotion identification accuracy.
The combination of complimentary data from diverse sources improves the systemâ€™s
accuracy and robustness.

## Model Architecture :
![model_architecture](https://github.com/user-attachments/assets/2af414d5-a95a-473f-a243-eaeb42a91107)

